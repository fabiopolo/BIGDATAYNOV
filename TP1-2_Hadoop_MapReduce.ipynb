{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiation à Hadoop et Map-Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'Objectif du TP: \n",
    "Initiation au framework hadoop et au patron MapReduce, utilisation de docker pour lancer un cluster hadoop.\n",
    "\n",
    "Pour réaliser le TP, on va utiliser ce Tuto Cloudera: https://www.cloudera.com/downloads/quickstart_vms/5-13.html\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "• Démarrer votre image docker\n",
    "\n",
    "• Créer un répertoire TP, puis deux sous-répertoires code et data dans lesquels sauvegarder   respectivement les codes des mappers et reducers, et les données sources et résultat.\n",
    "\n",
    "• Déplacez-vous sous le répertoire ~/TP/data, et y importer le fichier ventes.txt fourni\n",
    "\n",
    "Refs:\n",
    "Apache Hadoop [http://hadoop.apache.org/] \n",
    "\n",
    "Docker [https://www.docker.com/]\n",
    "\n",
    "Cloudera : https://www.cloudera.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### 1- Hadoop\n",
    "- Créer un répertoire dans HDFS, appelé data\n",
    "\n",
    "- Copier le fichier ventes.txt dans le répertoire data\n",
    "- Afficher le contenu du répertoire data et visualiser les dernières lignes du fichier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TBD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les commandes les plus utilisées dans Hadoop: \n",
    "hadoop fs –ls             Afficher le contenu du répertoire racine\n",
    "\n",
    "hadoop fs –put file.txt   Upload un fichier dans hadoop (à partir du répertoire courant linux)\n",
    "\n",
    "hadoop fs –get file.txt   Download un fichier à partir de hadoop sur votre disque local\n",
    "\n",
    "hadoop fs –tail file.txt  Lire les dernières lignes du fichier\n",
    "\n",
    "hadoop fs –cat file.txt   Affiche tout le contenu du fichier\n",
    "\n",
    "hadoop fs –mv file.txt newfile.txt   Renommer le fichier\n",
    "\n",
    "hadoop fs –rm newfile.txt            Supprimer le fichier\n",
    "\n",
    "hadoop fs –mkdir myinput             Créer un répertoire\n",
    "\n",
    "hadoop fs –cat file.txt | less       Lire le fichier page par page\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-  Map Reduce\n",
    "Un Job Map-Reduce se compose principalement de deux types de programmes:\n",
    "\n",
    "Mappers : permettent d’extraire les données nécessaires sous forme de clef/valeur, pour pouvoir ensuite appliquer un sort\n",
    "Reducers : prennent un ensemble de données triées , et effectuent le traitement nécessaire sur ces données (somme, moyenne,total...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 \n",
    "Soit le dataset ventes.txt comportant 6 champs, séparés par des tabulations, de la forme suivante:\n",
    "\n",
    "date temps magasin produit coût paiement\n",
    "\n",
    "Le but est de déterminer le total des ventes par magasin.\n",
    "\n",
    "Créer un fichier mapper.py dans le répertoire code , qui permet de:\n",
    "- Séparer les différents champs par tabulation\n",
    "- Extraire les éléments à partir de ces champs, sous forme de clé/valeur (magasin,coût), Pour calculer les ventes par magasin.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tester votre mapper en local sur les 50 premières lignes du fichier ventes.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 \n",
    "Le Reducer permet de faire le traitement définit sur des entrées préalablement triées par Hadoop .\n",
    "sur les couples (magasin,coût), le Reducer fera la somme de tous les coûts pour un même magasin. \n",
    "\n",
    "Ecrire le code du Reducer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester votre Reducer en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3\n",
    "Lancer un job entier sur Hadoop =>  faire appel au mapper puis au reducer sur une entrée volumineuse, et obtenir à la fin un résultat, directement sur HDFS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécuter un job hadoop sur le fichier ventes.txt en utilisant les fichiers mapper.py et reducer.py déjà implémentés. \n",
    "Stocker le résultat dans un répertoire joboutput. \n",
    "Sauvegarder ensuite le fichier part-00000 dans votre répertoire local.\n",
    "\n",
    "- Quelle est la totalité des ventes du magasin de Buffalo ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donner la liste des ventes par catégorie de produits.\n",
    "- Quelle est la valeur des ventes pour la catégorie Toys?\n",
    "- Et pour la catégorie Consumer Electronics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donner le montant de la vente le plus élevé pour chaque magasin\n",
    "- Quelle est cette valeur pour les magasins suivants:\n",
    "\n",
    "o Reno\n",
    "\n",
    "o Toledo\n",
    "\n",
    "o Chandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quel est le nombre total des ventes et la valeur totale des ventes de tous magasins\n",
    "confondus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour aller plus loin, construire votre cluster Hadoop de 3 Noeuds en définissant 3 containers: un noeud maître (Namenode) et deux noeuds esclaves\n",
    "(Datanodes).\n",
    "\n",
    "Refaire l'ex précedent sur votre nouveau ecosystème.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
